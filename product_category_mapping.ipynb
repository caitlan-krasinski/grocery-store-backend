{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/CaitlanKrasinski/miniconda3/lib/python3.8/site-packages (1.3.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/CaitlanKrasinski/miniconda3/lib/python3.8/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/CaitlanKrasinski/miniconda3/lib/python3.8/site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/CaitlanKrasinski/miniconda3/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/CaitlanKrasinski/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.14.0)\n",
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas \n",
    "! pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/CaitlanKrasinski/miniconda3/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dairy = pd.read_csv('csv_files/zehrs/dairy_and_eggs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>product_name</th>\n",
       "      <th>price</th>\n",
       "      <th>per_unit_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dairy_and_eggs</td>\n",
       "      <td>NeilsonPartly Skimmed Milk 2% MF4 l</td>\n",
       "      <td>$5.69ea</td>\n",
       "      <td>$0.14/ 100ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dairy_and_eggs</td>\n",
       "      <td>NeilsonPartly Skimmed Milk 1% MF4 l</td>\n",
       "      <td>$5.69ea</td>\n",
       "      <td>$0.14/ 100ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dairy_and_eggs</td>\n",
       "      <td>Gray RidgePremium Large Eggs18 eggs</td>\n",
       "      <td>$6.89ea</td>\n",
       "      <td>$0.38/ 1ea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dairy_and_eggs</td>\n",
       "      <td>NeilsonHomogenized Milk 3.25%4 l</td>\n",
       "      <td>$6.69ea</td>\n",
       "      <td>$0.17/ 100ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dairy_and_eggs</td>\n",
       "      <td>NeilsonTrue Taste, 2% Milk2 l</td>\n",
       "      <td>$5.49ea</td>\n",
       "      <td>$0.27/ 100ml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                         product_name    price per_unit_price\n",
       "0  dairy_and_eggs  NeilsonPartly Skimmed Milk 2% MF4 l  $5.69ea   $0.14/ 100ml\n",
       "1  dairy_and_eggs  NeilsonPartly Skimmed Milk 1% MF4 l  $5.69ea   $0.14/ 100ml\n",
       "2  dairy_and_eggs  Gray RidgePremium Large Eggs18 eggs  $6.89ea     $0.38/ 1ea\n",
       "3  dairy_and_eggs     NeilsonHomogenized Milk 3.25%4 l  $6.69ea   $0.17/ 100ml\n",
       "4  dairy_and_eggs        NeilsonTrue Taste, 2% Milk2 l  $5.49ea   $0.27/ 100ml"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dairy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets say a users search term is \n",
    "search_term = '2% Milk'\n",
    "\n",
    "# and we have a product \n",
    "product = 'NeilsonPartly Skimmed Milk 2% MF4 l'\n",
    "\n",
    "# similarity: \n",
    "sim = fuzz.partial_ratio(product.lower(), search_term.lower())\n",
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ kinda low "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compared to if the search term is \n",
    "search_term = 'Milk 2%'\n",
    "\n",
    "# and we have a product \n",
    "product = 'NeilsonPartly Skimmed Milk 2% MF4 l'\n",
    "\n",
    "# similarity: \n",
    "sim = fuzz.partial_ratio(product.lower(), search_term.lower())\n",
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ this is good, we want this as high as possible. but people probably wouldnt default to this, they would do the one before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now what if we break up search terms into each word\n",
    "search_term = 'Milk 2%'\n",
    "product = 'NeilsonPartly Skimmed Milk 2% MF4 l'\n",
    "\n",
    "total_ratio = 0\n",
    "for term in search_term.split():\n",
    "    sim = fuzz.partial_ratio(product.lower(), term.lower())\n",
    "    total_ratio += sim\n",
    "\n",
    "total_ratio / len(search_term.split()) # essentially the avg ratio value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ I think thats a good solution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoping some things out: \n",
    "\n",
    "Say someone searches 2% milk - we then have to retrieve it from the data \n",
    "\n",
    "A few things I think we have to do:\n",
    "\n",
    "1. Categorize the search term to match our data categories (eg: bakery, dairy_and_eggs, meat, etc) \n",
    "2. Search that dataset as above to find top ranking products for each store and flyer data set \n",
    "\n",
    "I think the best way to achieve 1. is with a classifier \n",
    "\n",
    "pretty much we would need to extract keywords from all our products (or split product names into seprate strings and each string would then be matched to a category) \n",
    "\n",
    "Train a classifier on that data ^ \n",
    "\n",
    "Input a search term and then output a category pred and then search that dataset (would need the prediction to be pretty high to be confident) \n",
    "\n",
    "Another idea - put all data into one dataset/csv and then we can just loop through every product - honestly given the dataset size and how fast we can similarity match, I think that is doable from a runtime perspective even though it seems like a lazy idea (it'd be a good start for a MVP) \n",
    "\n",
    "- we can start with this and if we find its too slow then we can go from there on a more complex solution, this is a good jumping off point \n",
    "\n",
    "I still nee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
